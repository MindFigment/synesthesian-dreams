
# Name of this experiment
exp_name: "dcgan_even_longer"

# GAN trainer
trainer: "DCGAN"

##################
## Train config ##
##################

t_c:

  want_log: True

  # Setup image size, it's here because we need it in trainer and model classes
  img_size: 64

  # Basic utilities
  save: True
  save_every: 20 # After how many epochs save the model
  # Saving options
  save_ext: ".pt"

  load: True
  load_config: False # Some parameters don't have to be updated: lr, beta1, beta2, loss_criterion
  load_netD: True
  load_netG: True
  load_optimD: True
  load_optimG: True
  load_model: "experiments/dcgan_64_100_lr05/checkpoints/220.pt"
  # load_model: "./checkpoints/base_model/5.pt"

  test: True
  test_every: 10 # After how many epochs test the model
  sample_size: 16 # How many samples to produce during testing

  # Training characterization
  batch_size: 512
  shuffle: True
  num_workers: 6
  epochs: 100

  # Data root
  data_roots: ["./data/best_artworks_of_all_time/normal", "./data/wikiart"]
  # data_roots: ["./data/best_artworks_of_all_time/normal"]

##################
## Model config ##
##################

m_c:

  # Learning options
  lr: 1e-5
  beta1: 0.4
  beta2: 0.999
  nz: 100
  ndf: 64
  ngf: 64
  nc: 3
  loss_criterion: "BCE"
  use_gpu: True

  ######################
  ## Scheduler config ##
  ######################

  use_schedulerD: False
  # schedulerD_name: "ReduceRLOnPlateau"
  schedulerD_name: "Cosine"

  sD_c:
    # factor: 0.05 
    # patience: 10 
    # min_lr: 0.0001
    verbose: False

  use_schedulerG: False
  # schedulerG_name: "ReduceRLOnPlateau"
  schedulerG_name: "Cosine"

  sG_c:
    # factor: 0.05 
    # patience: 10 
    # min_lr: 0.0001
    verbose: False